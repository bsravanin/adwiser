GOALS
Why was an ad shown?
	Was it targeted on a D or a R/X?
	If targeted on a D, which D?


ASSUMPTIONS
If targeted on at least one email thread (found in ccloudauditor2* or not found in ccloudauditor1*): Ds
Else if targeted on os, browser, gmail, location, career, cars, money, music, future event (black friday): Xs
Else if rarely repeated with and across accounts: Rs

KNOWLEDGE
Some ads are targeted on Ds (emails).
Ratio of number of targeted ads and number of trials is a decreasing function.
Targeted ads are repeated across accounts with common Ds.
Xs are repeated across similar accounts even with no common Ds.


GRAPHS


TODOS
False positives and false negatives in alpha^b * beta^c.
When do and don't precision Vs recall graphs make sense.
Performance when varying the base trial.
Performance of other exponentiation models.
Performance of aggregation models.
Selenium parallel.

LOWPRI TODOS
What is a better experiment setup? What mails in mailbox of real account? What division of mails in shadow accounts?
What makes a good scoring model for predictions?
Improve ad matching. May be more complicated, but to increase precision while not sacrificing recall.


DONE
1. Ad matching: find precision and recall.
	foreach (ad1, ad2), 1 if ads are same and 0 otherwise.
	90% precision and 80% recall is a good matching model.
	If good matching model, ignore ad matching.
	Matching with only exact match of AdURL/Text: 487 TPs, 53 FPs, 28 FNs
	Precision: 0.9018518518518519, Recall: 0.945631067961165
2. ads Vs trials graph.
	Knee around 33 trials for ccloudauditor10-30.
	Knees 3, 4 for ccloudauditor, ccloudauditor2.
3. Common ads in identical accounts.
4. Common ads in disjoint accounts.
5. Order by recall, not precision. Recall is a monotonic function. Precision is not.
6. Full truth, including types.
7. Targeted ads Vs Trials, TargetedX ads Vs Trials, Random Vs Trials graphs.
8. Ad types in identical accounts.
9. Verified whether varying the subset (or order) of trials varies the knee. (Say, in identical accounts.)
10. Cleanup page on disjoint accounts, including more useful graphs. One graph of all (1x, 2x) combinations and another of all (2x, 1x) combinations.
11. Various graphs, including precision Vs recall:
		foreach (alpha, beta, model) threshold on x-axis.
		foreach (threshold, alpha, model) beta on x-axis.
		foreach (threshold, beta, model) alpha on x-axis.
12. New disjoint accounts, threads, trials, truth, comparisons.
13. Models with all combinations of (alpha, beta), (a, b, c, d). All models give identical results.
14. Aggregation models. Normalizing scores a big problem, and could be the cause of bad results.
15. Aggregation and exponentiation models using both penalties and both rewards.
16. NO MORE NORMALIZATION.
17. Parallelized computation of precision and recall for various model, alpha, beta, threshold combinations. (Threshold now a function of alpha and beta.)

LOWPRI DONE
1. Describe args and returns along with the purpose for all functions.
2. Area under precision and recall curve is the efficiency of a model.
